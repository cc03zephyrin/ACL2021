{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this noteboke is to run several horse races, it will contain a sampling function taking input of texts and outputs of labels and authors\n",
    "# performing biased and unbiased sampling\n",
    "\n",
    "\n",
    "import itertools\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import scipy\n",
    "\n",
    "# from tensorflow.contrib.layers import fully_connected\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow_probability as tfp\n",
    "import math\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation, strip_multiple_whitespaces, remove_stopwords\n",
    "\n",
    "import re\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM, Input, Concatenate, GRU\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.utils import resample\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define global variables\n",
    "\n",
    "datapath = r'/home/cczephyrin/projects/political embedding/training_vec/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "# df = pd.read_csv(r'/home/cczephyrin/projects/political embedding/data/crs_1991_2020-10-04_sorted_filtered.csv', sep = '\\t', encoding= 'ISO-8859-1', index_col =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(x, CUSTOM_FILTERS = [strip_tags, strip_punctuation, strip_multiple_whitespaces, remove_stopwords]):\n",
    "\n",
    "    regex = re.compile('[^a-zA-Z ]')\n",
    "    corpus = regex.sub('', x)\n",
    "#     print(regex.sub(\"\", 'era 23'))\n",
    "    corpus = re.sub('\\s+', ' ', corpus)\n",
    "\n",
    "    sentences = preprocess_string(corpus, CUSTOM_FILTERS)\n",
    "    return \" \".join(sentences)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['processed_speech'] = df['speech'].apply(lambda x: process_text(x))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speech_id</th>\n",
       "      <th>true_id</th>\n",
       "      <th>chamber</th>\n",
       "      <th>state</th>\n",
       "      <th>party</th>\n",
       "      <th>congress</th>\n",
       "      <th>daysafter</th>\n",
       "      <th>monthsafter</th>\n",
       "      <th>speech</th>\n",
       "      <th>date</th>\n",
       "      <th>topics_prior</th>\n",
       "      <th>processed_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1020000029</td>\n",
       "      <td>M000811</td>\n",
       "      <td>S</td>\n",
       "      <td>ME</td>\n",
       "      <td>D</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mr. presdient. i will momentarily suggest the ...</td>\n",
       "      <td>19910103</td>\n",
       "      <td>22</td>\n",
       "      <td>mr presdient momentarily suggest absence quoru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1020000077</td>\n",
       "      <td>M000811</td>\n",
       "      <td>S</td>\n",
       "      <td>ME</td>\n",
       "      <td>D</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>. i send -to the desk en bloc 12 unanimouscons...</td>\n",
       "      <td>19910103</td>\n",
       "      <td>22</td>\n",
       "      <td>send desk en bloc unanimousconsent requests as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1020000084</td>\n",
       "      <td>M000811</td>\n",
       "      <td>S</td>\n",
       "      <td>ME</td>\n",
       "      <td>D</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>. the 12th of the series of requests does so p...</td>\n",
       "      <td>19910103</td>\n",
       "      <td>22</td>\n",
       "      <td>th series requests provide standard operating ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1020000088</td>\n",
       "      <td>M000811</td>\n",
       "      <td>S</td>\n",
       "      <td>ME</td>\n",
       "      <td>D</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the next item of business is a schedule of sen...</td>\n",
       "      <td>19910103</td>\n",
       "      <td>22</td>\n",
       "      <td>item business schedule senate activities perio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1020000105</td>\n",
       "      <td>H000206</td>\n",
       "      <td>S</td>\n",
       "      <td>IA</td>\n",
       "      <td>D</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>. i have a resolution. along with senator adam...</td>\n",
       "      <td>19910103</td>\n",
       "      <td>22</td>\n",
       "      <td>resolution senator adams senator burdick senat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    speech_id  true_id chamber state party  congress  daysafter  monthsafter  \\\n",
       "0  1020000029  M000811       S    ME     D       102          0            0   \n",
       "1  1020000077  M000811       S    ME     D       102          0            0   \n",
       "2  1020000084  M000811       S    ME     D       102          0            0   \n",
       "3  1020000088  M000811       S    ME     D       102          0            0   \n",
       "4  1020000105  H000206       S    IA     D       102          0            0   \n",
       "\n",
       "                                              speech      date  topics_prior  \\\n",
       "0  mr. presdient. i will momentarily suggest the ...  19910103            22   \n",
       "1  . i send -to the desk en bloc 12 unanimouscons...  19910103            22   \n",
       "2  . the 12th of the series of requests does so p...  19910103            22   \n",
       "3  the next item of business is a schedule of sen...  19910103            22   \n",
       "4  . i have a resolution. along with senator adam...  19910103            22   \n",
       "\n",
       "                                    processed_speech  \n",
       "0  mr presdient momentarily suggest absence quoru...  \n",
       "1  send desk en bloc unanimousconsent requests as...  \n",
       "2  th series requests provide standard operating ...  \n",
       "3  item business schedule senate activities perio...  \n",
       "4  resolution senator adams senator burdick senat...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(801422,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_switchers_ = ['A000361','B000229', 'B001264', 'D000168', 'G000280', 'H000067', 'H000390', 'L000119', 'P000066', 'T000058', 'C000077','F000257', 'G000557', \n",
    "'S000320', 'S000709','J000072']\n",
    "\n",
    "independents = ['S000033', 'B001237', 'K000383']\n",
    "\n",
    "true_switchers =independents + true_switchers_\n",
    "enddate = '2020-10-04'\n",
    "# bottom= FLAGS.bottom\n",
    "\n",
    "date = np.load(os.path.join(datapath, 'sorted_date_1991_{}.npy'.format(enddate)))\n",
    "\n",
    "inx = date>20090000\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "date.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data and save them\n",
    "# data_baseline = df.loc[inx, ['processed_speech', 'speech_id']]\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_baseline.to_csv(datapath + 'prcoessed_text_baseline.csv', sep ='\\t', encoding = 'ISO-8859-1', index_label = False)\n",
    "data_baseline = pd.read_csv(datapath + 'prcoessed_text_baseline.csv', sep ='\\t', encoding = 'ISO-8859-1', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define sampling functions, load As, dws, allow biased unbiased sampling\n",
    "\n",
    "As_all = np.load(os.path.join(datapath, 'cr_author_dummy_1991_{}.npy'.format(enddate)))[inx]\n",
    "\n",
    "parties_all = np.load(os.path.join(datapath, 'cr_parties_1991_{}.npy'.format(enddate)))[inx]\n",
    "\n",
    "As_ids = np.load(os.path.join(datapath, 'cr_author_id_1991_{}.npy'.format(enddate)),allow_pickle=True)\n",
    "\n",
    "dws_all = np.float32(np.load(os.path.join(datapath, 'cr_authordw_bydoc_1991_{}.npy'.format(enddate))))[inx][:, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((208292, 2), (208292,), (208292, 1674))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_baseline.shape, dws_all.shape, As_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(biased = True, notmask = 0.8):\n",
    "\n",
    "\n",
    "    switchdummies = [list(As_ids).index(i) for i in true_switchers if i in As_ids]\n",
    "\n",
    "    switch_speech_bool = As_all[:, switchdummies].sum(axis = -1)==1\n",
    "\n",
    "    # sum(switch_speech_bool),len(switch_speech_bool)\n",
    "\n",
    "    switch_id = np.arange(len(switch_speech_bool))[switch_speech_bool]\n",
    "    train_id_wo_switchers = np.setdiff1d(np.arange(len(As_all)), switch_id) # for model eval, exclude switchers, add them back for insights\n",
    "    # sss = StratifiedShuffleSplit(n_splits=1, test_size=.2)\n",
    "    # train_id, test_id = next(sss.split(As_all, parties_all))\n",
    "\n",
    "\n",
    "    # train_id_wo_switchers = np.setdiff1d(train_id, switch_id)\n",
    "    #test_id_wo_switchers = np.union1d(test_id, switch_id)\n",
    "\n",
    "    # test_id_wo_switchers = np.setdiff1d(test_id, switch_id)\n",
    "\n",
    "#     print(sum(switch_speech_bool),len(switch_speech_bool))\n",
    "\n",
    "    As_ns = As_all[train_id_wo_switchers]\n",
    "\n",
    "    parties_ns = parties_all[train_id_wo_switchers]\n",
    "    dws_ns = dws_all[train_id_wo_switchers]\n",
    "\n",
    "\n",
    "    if not biased:\n",
    "        sss = StratifiedShuffleSplit(n_splits=5, test_size= 1- notmask)\n",
    "        train_, test_= next(sss.split(As_ns, parties_ns))\n",
    "        train_id, test_id = train_id_wo_switchers[train_], train_id_wo_switchers[test_]\n",
    "        print(len(train_id), len(test_id))\n",
    "    else:\n",
    "        print('start biased sampling')\n",
    "        orderid = np.argsort(dws_ns)\n",
    "        train_id_wo_switchers_or = train_id_wo_switchers[orderid]\n",
    "        tbn = int(len(parties_ns) * notmask/2)\n",
    "        train_id = np.concatenate([train_id_wo_switchers_or[:tbn], train_id_wo_switchers_or[-tbn:]])\n",
    "        test_id = train_id_wo_switchers_or[tbn:-tbn]\n",
    "        print(len(train_id), len(test_id))\n",
    "        train_id = shuffle(train_id)\n",
    "        test_id = shuffle(test_id)\n",
    "    return train_id, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1393 208292\n",
      "165519 41380\n"
     ]
    }
   ],
   "source": [
    "# train_id, test_id = sample(biased = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 91176,  16696, 163486, ..., 135294, 151637,  21222]),\n",
       " array([150214,  83321,  64532, ..., 112115,  98160,  87683]))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_id, test_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training on models\n",
    "\n",
    "data= data_baseline['processed_speech'].values\n",
    "pty = parties_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5199130014499759"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pty[test_id].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "26.0\n",
      "5\n",
      "34.0\n",
      "10\n",
      "43.0\n",
      "15\n",
      "55.0\n",
      "20\n",
      "66.0\n",
      "25\n",
      "75.0\n",
      "30\n",
      "84.0\n",
      "35\n",
      "92.0\n",
      "40\n",
      "101.0\n",
      "45\n",
      "112.0\n",
      "50\n",
      "127.0\n",
      "55\n",
      "145.0\n",
      "60\n",
      "165.0\n",
      "65\n",
      "188.0\n",
      "70\n",
      "216.0\n",
      "75\n",
      "250.0\n",
      "80\n",
      "293.0\n",
      "85\n",
      "350.0\n",
      "90\n",
      "444.0\n",
      "95\n",
      "658.0\n"
     ]
    }
   ],
   "source": [
    "# for n in np.arange(0,100, 5):\n",
    "#     print(n)\n",
    "#     print(np.percentile(xlens, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1], dtype=int32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bi-directional lstm\n",
    "\n",
    "def bi_lstm_sample(data, pty, maxlen = 300, max_features = max_features):\n",
    "    tokenizer = Tokenizer(num_words=max_features, split=' ')\n",
    "    tokenizer.fit_on_texts(data)\n",
    "    X = tokenizer.texts_to_sequences(data)\n",
    "    X = pad_sequences(X, maxlen= maxlen)\n",
    "    y = pty\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bi_lstm(X, y, train_id, test_id,  batch_size = 500, n_epoch = 10, max_features = 100000, trial = False): # 80% padding, 20% trancate\n",
    "    if trial:\n",
    "        num = -1000\n",
    "        nu = -100\n",
    "        n_epoch = 1\n",
    "    else:\n",
    "        num = 0\n",
    "        nu= 0\n",
    "    X_train, X_test = X[train_id][num:], X[test_id][nu:]\n",
    "    maxlen = X.shape[1]\n",
    "    \n",
    "\n",
    "    print(\"train, test shape\", X_train.shape, X_test.shape)\n",
    "    y_train, y_test = y[train_id][num:], y[test_id][nu:]\n",
    "    sequence = Input(shape=(maxlen,), dtype='int32')\n",
    "    embedded = Embedding(max_features, 300, input_length=maxlen)(sequence)\n",
    "    forwards = GRU(100)(embedded)\n",
    "#     backwards = LSTM(100, go_backwards=True)(embedded)\n",
    "#     merged = Concatenate(axis = -1)([forwards, backwards])\n",
    "    after_dp = Dropout(0.5)(forwards)\n",
    "    inter = Dense(100, activation = 'relu')(after_dp)\n",
    "    output = Dense(1, activation='sigmoid')(inter)\n",
    "    model = Model(sequence, output)\n",
    "    model.compile('adam', 'binary_crossentropy', metrics=['accuracy'])\n",
    "    print('Train...')\n",
    "    model.fit(X_train, y_train, \n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epoch)\n",
    "    \n",
    "\n",
    "    \n",
    "    y_= model.predict(X_test)\n",
    "    y_pred= np.squeeze(y_)>=0.5\n",
    "    # print(y_)\n",
    "    # print(y_test)\n",
    "    acc = (y_pred == y_test).mean()\n",
    "    print('test accuracy', acc)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "\n",
    "def RF_sample(data, pty, max_features = 5000):\n",
    "    vector = CountVectorizer(max_features = max_features, dtype = np.uint16)\n",
    "    vector.fit(data)\n",
    "    a = vector.transform(data)\n",
    "    return a.toarray(), pty\n",
    "\n",
    "def RF_train(X, y, train_id, test_id, trial = False, max_features = 5000):\n",
    "    if trial:\n",
    "        num = -1000\n",
    "        nu = -100\n",
    "        n_epoch = 1\n",
    "    else:\n",
    "        num = 0\n",
    "        nu= 0\n",
    "    X_train, X_test = X[train_id][num:], X[test_id][nu:]\n",
    "\n",
    "    print(\"train, test shape\", X_train.shape, X_test.shape)\n",
    "    y_train, y_test = y[train_id][num:], y[test_id][nu:]\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth = 10, min_samples_split = 50,  min_samples_leaf = 10, \n",
    "                               warm_start=True, oob_score=True)\n",
    "    model.fit(X_train, y_train)\n",
    "    accuracy = model.oob_score_\n",
    "    print('oob acc is ', accuracy)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(y_pred)\n",
    "    acc = (y_pred==y_test).mean()\n",
    "    return acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X,y = RF_sample(data, pty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.595\n",
      "[1 1 1 1 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1\n",
      " 1 1 1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1\n",
      " 1 1 0 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 0 1 1 1 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# acc = RF_train(X, y, train_id, test_id, trial = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = bi_lstm_sample(data, pty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def repeated teset\n",
    "\n",
    "\n",
    "\n",
    "def repeated_test(data, pty, repeat= 5, method = 'gru', model_funcs = [bi_lstm_sample, bi_lstm], biased = True, notmask = 0.05):\n",
    "    accs = []\n",
    "    global max_features\n",
    "    global toy\n",
    "    dataf, trainf = model_funcs\n",
    "    print('begin training {}'.format(method))\n",
    "    X, y = dataf(data, pty, max_features = max_features)\n",
    "    accs = []\n",
    "\n",
    "    for i in range(repeat):\n",
    "        train_id, test_id = sample(biased = biased, notmask = notmask)\n",
    "\n",
    "        acc = trainf(X, y, train_id, test_id, trial = toy, max_features = max_features)\n",
    "        accs.append(acc)\n",
    "    return accs\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiments(data, pty,models_names = ['gru'], models_dict = {'gru': [bi_lstm_sample, bi_lstm]}, notmasks = [0.01, 0.03, 0.05, 0.08, 0.2, 0.4, 0.6, 0.8]):\n",
    "    for md in models_names:\n",
    "        for biased in [True, False]:\n",
    "            f = open( r'/home/cczephyrin/projects/political embedding/results/baselines/{}_{}.csv'.format(md, biased), 'w')\n",
    "            for notmask in notmasks:\n",
    "            \n",
    "                version = \"{}_{}_{}\".format(md, notmask, biased)\n",
    "\n",
    "                print(version)\n",
    "                model_funcs = models_dict[md]\n",
    "                accs = repeated_test(data, pty, method = md, model_funcs = model_funcs, biased = biased, notmask= notmask)\n",
    "                print(accs)\n",
    "                f.write(version)\n",
    "                for ac in accs:\n",
    "                    f.write('\\t'+ str(ac))\n",
    "                f.write('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF_0.01_True\n",
      "begin training RF\n",
      "1393 208292\n",
      "start biased sampling\n",
      "2068 204831\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.832\n",
      "[1 0 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 1 1 0 1 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 1 0 1 0 1 1 1 0 0 1 1 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 1 0 0 0 0 1 1\n",
      " 0 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0]\n",
      "1393 208292\n",
      "start biased sampling\n",
      "2068 204831\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.847\n",
      "[1 0 0 0 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 1 1 1 0 0 0\n",
      " 0 1 1 0 0 1 0 0 0 0 1 0 1 0 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1 0 0 1 0 1 1 1 1\n",
      " 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 0 1 0 1 1 0 1 1 0 0]\n",
      "1393 208292\n",
      "start biased sampling\n",
      "2068 204831\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.831\n",
      "[0 0 1 0 1 1 0 0 1 0 1 1 1 1 0 0 0 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 1 0 1 0\n",
      " 1 1 1 1 1 1 1 0 1 0 1 1 0 0 0 1 1 0 0 0 0 0 1 0 0 1 1 1 0 0 1 1 1 1 1 1 0\n",
      " 0 1 0 1 0 1 0 0 1 0 0 1 1 0 0 1 0 0 1 1 0 1 0 1 1 0]\n",
      "1393 208292\n",
      "start biased sampling\n",
      "2068 204831\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.838\n",
      "[0 0 0 0 0 0 0 1 1 1 0 1 0 0 1 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 1 1 0 0\n",
      " 0 1 1 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1\n",
      " 0 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 0 1]\n",
      "1393 208292\n",
      "start biased sampling\n",
      "2068 204831\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.828\n",
      "[1 0 1 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 1 1 0 1 1 1 0 0 0 0 0\n",
      " 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 0 0 1 0 1 0 0 0 1 0 0 0\n",
      " 1 0 0 1 0 0 0 1 1 1 0 1 1 1 0 1 0 0 0 1 0 1 0 1 1 1]\n",
      "[0.54, 0.58, 0.55, 0.59, 0.57]\n",
      "RF_0.03_True\n",
      "begin training RF\n",
      "1393 208292\n",
      "start biased sampling\n",
      "6206 200693\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.803\n",
      "[1 1 1 1 0 0 1 0 0 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 0 0 0 0 0 1 0 0 0 0 1 1\n",
      " 1 0 1 0 1 0 0 0 1 1 1 0 0 1 0 0 1 1 0 1 0 1 0 0 0 1 1 0 0 0 1 1 0 0 0 1 1\n",
      " 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0]\n",
      "1393 208292\n",
      "start biased sampling\n",
      "6206 200693\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.817\n",
      "[1 0 0 1 0 0 0 1 0 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 0 0 1 0 0 1 0 1 1\n",
      " 0 1 0 0 1 0 1 0 1 0 0 0 0 1 1 0 0 0 1 1 1 0 1 0 1 1 1 0 0 1 0 1 1 0 1 0 0\n",
      " 1 0 1 1 1 0 1 1 1 1 0 0 1 1 1 1 0 0 1 1 0 1 1 1 1 1]\n",
      "1393 208292\n",
      "start biased sampling\n",
      "6206 200693\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.811\n",
      "[1 0 0 0 0 1 1 1 1 1 0 1 1 1 1 1 0 0 0 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1 0\n",
      " 0 0 1 1 0 0 0 0 0 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 1 1\n",
      " 0 0 0 1 0 0 0 1 0 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 1 0]\n",
      "1393 208292\n",
      "start biased sampling\n",
      "6206 200693\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.785\n",
      "[1 1 0 0 0 0 1 1 0 1 1 1 1 0 0 1 1 0 1 0 0 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 0\n",
      " 0 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0\n",
      " 0 0 0 0 1 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 1]\n",
      "1393 208292\n",
      "start biased sampling\n",
      "6206 200693\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.814\n",
      "[1 1 0 0 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0 1 1 0\n",
      " 0 0 0 0 1 0 0 1 0 0 1 0 1 0 1 1 0 0 1 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 1 1 1\n",
      " 0 0 1 0 1 0 1 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 1 1 1]\n",
      "[0.55, 0.63, 0.55, 0.52, 0.56]\n",
      "RF_0.01_False\n",
      "begin training RF\n",
      "1393 208292\n",
      "2068 204831\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.619\n",
      "[0 0 1 0 1 0 1 0 1 1 0 1 1 0 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1 1\n",
      " 0 0 1 1 1 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 1 0 1 0 1 1 0 0 0 1 0 0 1 0 0 0 1\n",
      " 1 0 1 0 0 1 0 1 0 0 0 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0]\n",
      "1393 208292\n",
      "2068 204831\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.623\n",
      "[1 1 1 0 1 0 1 1 1 0 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 0 1 1\n",
      " 1 1 0 1 1 1 0 1 1 0 0 0 1 0 1 0 1 0 1 1 1 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1\n",
      " 1 0 0 1 1 0 1 1 0 0 1 1 1 0 0 1 1 0 1 0 1 1 0 1 0 1]\n",
      "1393 208292\n",
      "2068 204831\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.597\n",
      "[1 1 1 0 1 1 1 0 1 0 1 0 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1]\n",
      "1393 208292\n",
      "2068 204831\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.58\n",
      "[1 1 1 0 0 1 1 0 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1\n",
      " 0 1 0 0 1 1 0 1 1 0 0 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1 1 1 0 1 1 0 0 1 0 0 1]\n",
      "1393 208292\n",
      "2068 204831\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.583\n",
      "[0 0 0 1 1 0 0 1 1 1 1 1 0 1 0 0 1 0 0 0 0 1 0 1 0 0 1 1 0 0 1 1 0 1 1 0 0\n",
      " 0 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 0 0 0 0 0 0\n",
      " 0 0 1 1 1 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 1 1 1 0]\n",
      "[0.57, 0.65, 0.54, 0.71, 0.64]\n",
      "RF_0.03_False\n",
      "begin training RF\n",
      "1393 208292\n",
      "6206 200693\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.622\n",
      "[0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1\n",
      " 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 0 0 1 1 1\n",
      " 0 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 1 1 1 1 1 0]\n",
      "1393 208292\n",
      "6206 200693\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.565\n",
      "[1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "1393 208292\n",
      "6206 200693\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.57\n",
      "[1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 0 0 0 1 1\n",
      " 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 1 1]\n",
      "1393 208292\n",
      "6206 200693\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.621\n",
      "[1 1 1 1 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0\n",
      " 1 0 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 0 1 0 0 1 0 1 0 1 1 1 1 1 0 0 1 1 1 0 1\n",
      " 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 1 1 1 1 1 1]\n",
      "1393 208292\n",
      "6206 200693\n",
      "train, test shape (1000, 5000) (100, 5000)\n",
      "oob acc is  0.587\n",
      "[1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 0 1 1 1 1 0 1 1 0 0 1\n",
      " 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 1 1 0 0 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 0 1 0 1 0 1]\n",
      "[0.65, 0.53, 0.6, 0.68, 0.51]\n"
     ]
    }
   ],
   "source": [
    "# models_names = ['gru']\n",
    "# models_dict = {'gru': [bi_lstm_sample, bi_lstm]}\n",
    "models_names = ['RF']\n",
    "models_dict = {'RF': [RF_sample, RF_train]}\n",
    "\n",
    "toy= True\n",
    "# max_features = 100000\n",
    "max_features = 50000\n",
    "experiments(data, pty, models_names = models_names, models_dict = models_dict, notmasks = [0.01, 0.03])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
